
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Transfer Learning &#8212; RocketML 1.0.0 (RocketML Confidential) documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0.0 (RocketML Confidential)',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Reference" href="reference.html" />
    <link rel="prev" title="Applications" href="applications.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="transfer-learning">
<h1>Transfer Learning<a class="headerlink" href="#transfer-learning" title="Permalink to this headline">¶</a></h1>
<p>Transfer learning can be realized in <code class="code docutils literal"><span class="pre">rmldnn</span></code> by leveraging the checkpointing system described above,
and by making (hopefully small) changes to the network files. When training a network on dataset
<img class="math" src="_images/math/636c5daa08b9b147fb87ae06c68ae7d038e17d44.png" alt="D_1"/>, enable checkpoint saving with</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="s2">&quot;checkpoints&quot;</span>: <span class="o">{</span>
    <span class="s2">&quot;save&quot;</span>: <span class="s2">&quot;./checkpoints_D1/&quot;</span>
    <span class="s2">&quot;interval&quot;</span>: <span class="m">10</span>,
<span class="o">}</span>
</pre></div>
</div>
<p>Now, to transfer learning when training the same network with a new dataset <img class="math" src="_images/math/65c334c88befaad71f9d8dcc54cee7542f8d3785.png" alt="D_2"/>, load the model
saved during <img class="math" src="_images/math/636c5daa08b9b147fb87ae06c68ae7d038e17d44.png" alt="D_1"/> training:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="s2">&quot;checkpoints&quot;</span>: <span class="o">{</span>
    <span class="s2">&quot;load&quot;</span>: <span class="s2">&quot;./checkpoints_D1/model_checkpoint_100.pt&quot;</span>,
    <span class="s2">&quot;save&quot;</span>: <span class="s2">&quot;./checkpoints_D2/&quot;</span>
    <span class="s2">&quot;interval&quot;</span>: <span class="m">10</span>,
<span class="o">}</span>
</pre></div>
</div>
<p>Two main use cases can occur depending on the type of network:</p>
<p><strong>1. Purely convolutional networks</strong></p>
<p>In this case, the layers of the network are agnostic to the training sample sizes (as long as the tensors
have the same rank) and, therefore, do not need to be changed when transferring learning.
The only adjustment needed in the network file is the input size, usually defined in
the first layer (e.g., InputLayer):</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span><span class="o">{</span>
    <span class="s2">&quot;class_name&quot;</span>: <span class="s2">&quot;InputLayer&quot;</span>,
        <span class="s2">&quot;config&quot;</span>: <span class="o">{</span>
            <span class="s2">&quot;batch_input_shape&quot;</span>: <span class="o">[</span>
                null,
                <span class="m">128</span>,
                <span class="m">128</span>,
                <span class="m">1</span>
            <span class="o">]</span>,
        <span class="s2">&quot;dtype&quot;</span>: <span class="s2">&quot;float32&quot;</span>
        <span class="s2">&quot;name&quot;</span>: <span class="s2">&quot;input_1&quot;</span>,
    <span class="o">}</span>,
    <span class="s2">&quot;inbound_nodes&quot;</span>: <span class="o">[]</span>
<span class="o">}</span>
</pre></div>
</div>
<p><strong>2. Networks with fixed-size layers</strong></p>
<p>If the network contains layers whose configuration depends on the size of the training samples
(e.g., Dense), then the parameters for those layers cannot be transferred from a model trained
on a dataset with different size samples. In this case, those layers have to be renamed in the
network file and retrained with the new dataset. When loading the model, <code class="code docutils literal"><span class="pre">rmldnn</span></code> will warn
about layers whose parameters cannot be transferred:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>Loading model checkpoint from file: ./checkpoints_D1/model_checkpoint_100.pt
   Skipping layer dense_128_1: not found in model
   Skipping parameter dense_128_1.weight: not found in model
   Skipping parameter dense_128_1.bias: not found in model
...
</pre></div>
</div>
<p><strong>Application: multigrid training</strong></p>
<p>One can leverage transfer learning to emulate the multigrid method for solving PDEs by training
models of increasing resolution which are initialized from lower resolution ones. If the network
is fully convolutional, a model trained at a certain resolution (data size) can be completely
re-utilized when going to higher resolution (i.e., all layer parameters transferred). And even if
the network changes at different resolutions, at least part of the model can perhaps be re-utilized.</p>
<p>For example, in order to train a UNet whose depth increases with resolution, one could simply add
extra layers to the top part of the “U” and keep the bottom layers unchanged (see figure).
The added layers will be trained from scratch, but the majority of the
network (bottom part of the “U”) will be initialized from the model trained at lower resolution.</p>
<a class="reference internal image-reference" href="_images/unet2d_multigrid.png"><img alt="unet2d_multigrid.png" src="_images/unet2d_multigrid.png" style="width: 600px;" /></a>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="applications.html" title="previous chapter">Applications</a></li>
      <li>Next: <a href="reference.html" title="next chapter">Reference</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/transfer_learning.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, RocketML.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.7</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.8</a>
      
      |
      <a href="_sources/transfer_learning.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>